{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f645f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ec4c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available:\", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65196cde",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a809a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER ='DataSet\\Teeth Segmentation PNG\\d2\\img'\n",
    "MASK_FOLDER = 'DataSet\\Teeth Segmentation PNG\\d2\\masks_human'\n",
    "\n",
    "IMAGE_DIMENSION = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ee709d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T05:27:47.759151Z",
     "iopub.status.busy": "2024-10-19T05:27:47.758815Z",
     "iopub.status.idle": "2024-10-19T05:29:39.023823Z",
     "shell.execute_reply": "2024-10-19T05:29:39.022594Z"
    },
    "papermill": {
     "duration": 111.274611,
     "end_time": "2024-10-19T05:29:39.029159",
     "exception": false,
     "start_time": "2024-10-19T05:27:47.754548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 598 images and masks\n",
      "Training samples: 478, Validation samples: 120\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_images_and_masks(image_folder, mask_folder, image_dim=IMAGE_DIMENSION):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_files = os.listdir(image_folder)\n",
    "    \n",
    "    for img_name in image_files:\n",
    "        # Construct full paths\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        # Assuming mask has same name and .png extension\n",
    "        mask_name = os.path.splitext(img_name)[0] + '.png' \n",
    "        mask_path = os.path.join(mask_folder, mask_name)\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image file not found: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Warning: Mask file not found: {mask_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Read image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"Warning: Could not load mask: {mask_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize both image and mask\n",
    "        img = cv2.resize(img, image_dim)\n",
    "        mask = cv2.resize(mask, image_dim)\n",
    "        \n",
    "        # Convert mask to binary (Separates teeth (1) from background (0)) \n",
    "        mask = np.where(mask > 128, 1, 0)\n",
    "        \n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    \n",
    "    # Convert lists to numpy arrays and normalize images for better training\n",
    "    images = np.array(images) / 255.0 \n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    # Since it is grayscale images, extra dimension for channels is required\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "    masks = np.expand_dims(masks, axis=-1)\n",
    "    \n",
    "    print(f\"Successfully loaded {len(images)} images and masks\")\n",
    "    return images, masks\n",
    "\n",
    "# Load images and masks\n",
    "images, masks = load_images_and_masks(IMAGE_FOLDER, MASK_FOLDER)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Validation samples: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e562624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T05:29:39.037110Z",
     "iopub.status.busy": "2024-10-19T05:29:39.036451Z",
     "iopub.status.idle": "2024-10-19T05:29:40.217368Z",
     "shell.execute_reply": "2024-10-19T05:29:40.216335Z"
    },
    "papermill": {
     "duration": 1.187456,
     "end_time": "2024-10-19T05:29:40.219812",
     "exception": false,
     "start_time": "2024-10-19T05:29:39.032356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 512, 512, 64  640         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['conv2d_3[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['conv2d_4[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 128, 128, 51  0           ['conv2d_7[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 25  524544      ['up_sampling2d[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 51  0           ['conv2d_8[0][0]',               \n",
      "                                2)                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 25  1179904     ['concatenate[0][0]']            \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 25  590080      ['conv2d_9[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 25  0          ['conv2d_10[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 12  131200      ['up_sampling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_11[0][0]',              \n",
      "                                6)                                'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_1[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 12  147584      ['conv2d_12[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 12  0          ['conv2d_13[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 512, 512, 64  32832       ['up_sampling2d_2[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_14[0][0]',              \n",
      "                                8)                                'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 512, 512, 64  36928       ['conv2d_15[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 512, 512, 1)  65          ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,696,193\n",
      "Trainable params: 7,696,193\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def unet_model(input_size=(512, 512, 1)):\n",
    "    # Define input layer correctly\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    \n",
    "    # Rest of the model architecture remains the same\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Expansive Path (Decoder)\n",
    "    u5 = tf.keras.layers.UpSampling2D((2, 2))(c4)\n",
    "    u5 = tf.keras.layers.Conv2D(256, (2, 2), activation='relu', padding='same')(u5)\n",
    "    u5 = tf.keras.layers.Concatenate()([u5, c3])\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = tf.keras.layers.UpSampling2D((2, 2))(c5)\n",
    "    u6 = tf.keras.layers.Conv2D(128, (2, 2), activation='relu', padding='same')(u6)\n",
    "    u6 = tf.keras.layers.Concatenate()([u6, c2])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.UpSampling2D((2, 2))(c6)\n",
    "    u7 = tf.keras.layers.Conv2D(64, (2, 2), activation='relu', padding='same')(u7)\n",
    "    u7 = tf.keras.layers.Concatenate()([u7, c1])\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    # Create model with correct input specification\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "# Adam optimizer: Adaptive learning rate optimization\n",
    "# Binary cross-entropy loss: Suitable for binary segmentation\n",
    "# Accuracy metric: Measures correct pixel classifications\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', \n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f74351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# Configure GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0312532",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1c0081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T05:29:40.230694Z",
     "iopub.status.busy": "2024-10-19T05:29:40.230376Z",
     "iopub.status.idle": "2024-10-19T07:06:06.768902Z",
     "shell.execute_reply": "2024-10-19T07:06:06.767948Z"
    },
    "papermill": {
     "duration": 5786.546005,
     "end_time": "2024-10-19T07:06:06.770984",
     "exception": false,
     "start_time": "2024-10-19T05:29:40.224979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 82s 480ms/step - loss: nan - accuracy: 0.7902 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7806\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7811\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7902 - val_loss: nan - val_accuracy: 0.7808\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 47s 391ms/step - loss: nan - accuracy: 0.7903 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 47s 390ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7808\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 47s 390ms/step - loss: nan - accuracy: 0.7900 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 47s 394ms/step - loss: nan - accuracy: 0.7900 - val_loss: nan - val_accuracy: 0.7808\n",
      "30/30 [==============================] - 4s 118ms/step - loss: nan - accuracy: 0.7810\n",
      "Validation Loss: nan, Validation Accuracy: 0.7810076475143433\n"
     ]
    }
   ],
   "source": [
    "# Import necessary TensorFlow components\n",
    "from tensorflow.keras.optimizers import Adam  # For model optimization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy  # For binary segmentation loss\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping  # For training monitoring\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "# Clear any existing TensorFlow sessions to prevent memory issues\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Configure the model's training parameters\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),  # Use Adam optimizer with small learning rate\n",
    "    loss=BinaryCrossentropy(),  # Binary cross-entropy loss for segmentation\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Data Augmentation Function (Increase training data variety and improve model performance)\n",
    "def augment(image, mask):\n",
    "    \"\"\"\n",
    "    Apply random transformations to both image and mask to increase training data variety\n",
    "    \"\"\"\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Random 90-degree rotation (50% probability)\n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            image = tf.image.rot90(image)\n",
    "            mask = tf.image.rot90(mask)\n",
    "\n",
    "        # Random cropping to original size\n",
    "        # This helps model learn to handle different parts of the image\n",
    "        image = tf.image.random_crop(image, size=[IMAGE_DIMENSION[0], IMAGE_DIMENSION[1], 1])\n",
    "        mask = tf.image.random_crop(mask, size=[IMAGE_DIMENSION[0], IMAGE_DIMENSION[1], 1])\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        # Helps model learn invariance to left/right orientation\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        mask = tf.image.random_flip_left_right(mask)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "# Dataset Creation Function\n",
    "def create_dataset(X, y, batch_size=8):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset with data augmentation and optimization\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    \n",
    "    # Apply augmentation to each image-mask pair\n",
    "    # num_parallel_calls optimizes performance by parallel processing\n",
    "    dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Optimize dataset performance\n",
    "    dataset = dataset.shuffle(buffer_size=len(X))  # Shuffle data\n",
    "    dataset = dataset.batch(batch_size)  # Create batches\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)  # Prefetch next batch\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = create_dataset(X_train, y_train, batch_size=4)\n",
    "val_dataset = create_dataset(X_val, y_val, batch_size=4)\n",
    "\n",
    "# Training Callbacks Setup\n",
    "# ModelCheckpoint: Save the best model during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model.keras',  # Save model to this file\n",
    "    save_best_only=True,  # Only save the best model\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min'  # Lower is better\n",
    ")\n",
    "\n",
    "# EarlyStopping: Stop training if model stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=10,  # Stop after 10 epochs without improvement\n",
    "    mode='min'  # Lower is better\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,  # Training data\n",
    "    validation_data=val_dataset,  # Validation data\n",
    "    epochs=50,  # Number of training epochs\n",
    "    batch_size=4,  # Number of samples per batch\n",
    "    callbacks=[checkpoint, early_stopping],  # Training callbacks,\n",
    "    max_queue_size=10,\n",
    "    workers=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b354268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('teeth_segmentation_model_2.h5')  # HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ae56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "120/120 [==============================] - 48s 392ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 2/40\n",
      "120/120 [==============================] - 47s 392ms/step - loss: nan - accuracy: 0.7904 - val_loss: nan - val_accuracy: 0.7810\n",
      "Epoch 3/40\n",
      "120/120 [==============================] - 47s 393ms/step - loss: nan - accuracy: 0.7901 - val_loss: nan - val_accuracy: 0.7809\n",
      "Epoch 4/40\n",
      " 69/120 [================>.............] - ETA: 18s - loss: nan - accuracy: 0.7872"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteeth_segmentation_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Continue training\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history_continued \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Remaining epochs\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\vizvi\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('teeth_segmentation_model.h5')\n",
    "\n",
    "# Continue training\n",
    "history_continued = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=40,  # Remaining epochs\n",
    "    batch_size=2,\n",
    "    max_queue_size=5,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('teeth_segmentation_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ced3801",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Possible overfitting detected (training accuracy > validation accuracy)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Call the detailed plotting function\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[43mplot_training_history_detailed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m, in \u001b[0;36mplot_training_history_detailed\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mPlot training history with additional analysis and annotations\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Set style\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create figure with two subplots\u001b[39;00m\n\u001b[0;32m      9\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_history_detailed(history):\n",
    "    \"\"\"\n",
    "    Plot training history with additional analysis and annotations\n",
    "    \"\"\"\n",
    "    # Set style\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot Loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Find best epoch for validation loss\n",
    "    best_val_loss_epoch = np.argmin(val_loss) + 1\n",
    "    best_val_loss = min(val_loss)\n",
    "    \n",
    "    ax1.plot(train_loss, label='Training Loss', color='blue', linewidth=2)\n",
    "    ax1.plot(val_loss, label='Validation Loss', color='red', linewidth=2)\n",
    "    ax1.set_title('Model Loss Over Time', fontsize=14, pad=15)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Add annotation for best validation loss\n",
    "    ax1.annotate(f'Best Val Loss: {best_val_loss:.4f}\\nEpoch: {best_val_loss_epoch}',\n",
    "                xy=(best_val_loss_epoch-1, best_val_loss),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    # Find best epoch for validation accuracy\n",
    "    best_val_acc_epoch = np.argmax(val_acc) + 1\n",
    "    best_val_acc = max(val_acc)\n",
    "    \n",
    "    ax2.plot(train_acc, label='Training Accuracy', color='blue', linewidth=2)\n",
    "    ax2.plot(val_acc, label='Validation Accuracy', color='red', linewidth=2)\n",
    "    ax2.set_title('Model Accuracy Over Time', fontsize=14, pad=15)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Add annotation for best validation accuracy\n",
    "    ax2.annotate(f'Best Val Acc: {best_val_acc:.4f}\\nEpoch: {best_val_acc_epoch}',\n",
    "                xy=(best_val_acc_epoch-1, best_val_acc),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\nTraining Analysis:\")\n",
    "    print(f\"Best Validation Loss: {best_val_loss:.4f} at Epoch {best_val_loss_epoch}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f} at Epoch {best_val_acc_epoch}\")\n",
    "    print(\"\\nFinal Metrics:\")\n",
    "    print(f\"Training Loss: {train_loss[-1]:.4f}\")\n",
    "    print(f\"Training Accuracy: {train_acc[-1]:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss[-1]:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc[-1]:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    if train_loss[-1] < val_loss[-1]:\n",
    "        print(\"\\nWarning: Possible overfitting detected (training loss < validation loss)\")\n",
    "    if train_acc[-1] > val_acc[-1]:\n",
    "        print(\"Warning: Possible overfitting detected (training accuracy > validation accuracy)\")\n",
    "\n",
    "# Call the detailed plotting function\n",
    "plot_training_history_detailed(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d94acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T07:06:07.308138Z",
     "iopub.status.busy": "2024-10-19T07:06:07.307218Z",
     "iopub.status.idle": "2024-10-19T07:06:07.313977Z",
     "shell.execute_reply": "2024-10-19T07:06:07.313095Z"
    },
    "papermill": {
     "duration": 0.258039,
     "end_time": "2024-10-19T07:06:07.315872",
     "exception": false,
     "start_time": "2024-10-19T07:06:07.057833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e46b09",
   "metadata": {
    "papermill": {
     "duration": 0.245912,
     "end_time": "2024-10-19T07:06:07.810038",
     "exception": false,
     "start_time": "2024-10-19T07:06:07.564126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3381693,
     "sourceId": 5884500,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5920.123982,
   "end_time": "2024-10-19T07:06:11.877584",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T05:27:31.753602",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
